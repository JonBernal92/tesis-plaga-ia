package com.tesis.plagasia

import android.content.Context
import android.content.res.AssetFileDescriptor
import android.graphics.Bitmap
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel

/**
 * Clasificador de enfermedades en plantas de tomate mediante Deep Learning.
 *
 * Esta clase implementa un sistema de inferencia basado en TensorFlow Lite
 * para la detecci칩n autom치tica de cinco categor칤as de estados fitosanitarios
 * en cultivos de tomate mediante an치lisis de im치genes en tiempo real.
 *
 * Arquitectura: MobileNetV2 (optimizada para dispositivos m칩viles)
 * Entrada: Im치genes RGB de 224x224 p칤xeles
 * Salida: Vector de probabilidades para 5 clases
 *
 * @property context Contexto de la aplicaci칩n Android para acceso a assets
 */
class TomateClassifier(private val context: Context){

    // Int칠rprete del modelo TensorFlow Lite (motor de inferencia)
    private var interpreter: Interpreter? = null

    // Dimensiones de entrada requeridas por la arquitectura MobileNetV2
    // El modelo fue entrenado con im치genes cuadradas de 224x224 p칤xeles
    private val INPUT_SIZE = 224

    /**
     * Cat치logo de clases de salida del modelo.
     *
     * El orden de estas etiquetas debe coincidir exactamente con el orden
     * utilizado durante el entrenamiento del modelo (칤ndice 0 = primera clase, etc.)
     *
     * Clases reconocidas:
     * - 칈ndice 0: Planta sana (sin patolog칤as)
     * - 칈ndice 1: Tiz칩n temprano (Alternaria solani)
     * - 칈ndice 2: Hoja rizada (Virus del enrollamiento)
     * - 칈ndice 3: Mancha septoria (Septoria lycopersici)
     * - 칈ndice 4: Marchitez por Verticillium (Verticillium spp.)
     */
    private val labels = listOf(
        "Sano",
        "Tiz칩n Temprano",
        "Hoja Rizada",
        "Mancha Septoria",
        "Marchitez Verticillium"
    )

    init {
        // Inicializaci칩n del modelo durante la construcci칩n del objeto
        // El modelo se carga desde la carpeta 'assets' de la aplicaci칩n
        val model = loadModelFile("tomate_final_compatible.tflite")
        interpreter = Interpreter(model)
    }

    /**
     * Carga el archivo del modelo TensorFlow Lite desde assets.
     *
     * Utiliza mapeo de memoria (memory mapping) para acceso eficiente
     * sin cargar todo el archivo en RAM, optimizando el uso de recursos.
     *
     * @param modelName Nombre del archivo .tflite en la carpeta assets
     * @return ByteBuffer con el modelo mapeado en memoria
     * @throws IOException si el archivo no existe o no se puede leer
     */
    private fun loadModelFile(modelName: String): ByteBuffer {
        // Obtener descriptor del archivo desde assets
        val fileDescriptor: AssetFileDescriptor = context.assets.openFd(modelName)

        // Crear flujo de entrada desde el descriptor
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel: FileChannel = inputStream.channel

        // Par치metros de ubicaci칩n del archivo dentro del APK
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength

        // Mapear archivo directamente en memoria (eficiente para archivos grandes)
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

    /**
     * Clasifica una imagen de planta de tomate para an치lisis en tiempo real.
     *
     * Este m칠todo est치 optimizado para la vista previa de c치mara, aplicando
     * un umbral de confianza del 50% para reducir falsos positivos durante
     * el escaneo continuo.
     *
     * Proceso completo de inferencia:
     * 1. Redimensionamiento de imagen a 224x224
     * 2. Normalizaci칩n de p칤xeles al rango esperado por el modelo
     * 3. Ejecuci칩n de la red neuronal
     * 4. Interpretaci칩n de probabilidades de salida
     *
     * @param bitmap Imagen capturada por la c치mara del dispositivo
     * @return String con la clase predicha y porcentaje de confianza
     */
    fun classify(bitmap: Bitmap): String {
        // Validaci칩n de disponibilidad del int칠rprete
        if (interpreter == null) return "Error: Modelo no cargado"

        // PASO 1: PREPROCESAMIENTO DE IMAGEN
        // Redimensionamiento bilineal a las dimensiones requeridas (224x224)
        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, INPUT_SIZE, INPUT_SIZE, true)

        // PASO 2: CONVERSI칍N A FORMATO TENSOR
        // Transformaci칩n de Bitmap Android a ByteBuffer para TensorFlow Lite
        // Formato esperado: [1, 224, 224, 3] con valores float32 normalizados
        val byteBuffer = convertBitmapToByteBuffer(scaledBitmap)

        // PASO 3: PREPARACI칍N DEL CONTENEDOR DE SALIDA
        // Array bidimensional: [1 batch][5 clases]
        // Cada posici칩n almacenar치 la probabilidad (0.0 a 1.0) de cada clase
        val output = Array(1) { FloatArray(labels.size) }

        // PASO 4: EJECUCI칍N DE INFERENCIA
        // El int칠rprete ejecuta el modelo neuronal con la imagen preprocesada
        interpreter?.run(byteBuffer, output)

        // PASO 5: POST-PROCESAMIENTO DE RESULTADOS
        val probabilities = output[0]

        // B칰squeda de la clase con mayor probabilidad
        val maxIndex = probabilities.indices.maxByOrNull { probabilities[it] } ?: -1

        // Umbral de confianza: solo se reporta si la probabilidad supera 50%
        // Esto reduce falsos positivos en condiciones de iluminaci칩n deficiente
        if (maxIndex != -1 && probabilities[maxIndex] > 0.5f) {
            val confidence = (probabilities[maxIndex] * 100).toInt()
            return "${labels[maxIndex]}\n($confidence%)"
        } else {
            // Confianza insuficiente: se requiere mejor encuadre o iluminaci칩n
            return "Analizando..."
        }
    }

    /**
     * Clasifica una imagen mostrando TODOS los resultados con porcentajes.
     *
     * A diferencia de classify(), este m칠todo no aplica umbral de confianza
     * y muestra las probabilidades de todas las clases ordenadas de mayor a menor.
     *
     * 칔til para an치lisis detallado de im치genes de galer칤a donde el usuario
     * desea ver el desglose completo de probabilidades para todas las categor칤as,
     * permitiendo identificar diagn칩sticos secundarios o casos ambiguos.
     *
     * El resultado incluye:
     * - Emojis de medalla (游볞游볟游볠) para las tres predicciones principales
     * - Porcentajes redondeados para facilitar lectura
     * - Ordenamiento descendente por probabilidad
     *
     * @param bitmap Imagen a clasificar (t칤picamente desde galer칤a)
     * @return String formateado con todas las clases y sus porcentajes
     */
    fun classifyWithAllResults(bitmap: Bitmap): String {
        // Validaci칩n de disponibilidad del int칠rprete
        if (interpreter == null) return "Error: Modelo no cargado"

        // Preprocesamiento id칠ntico al m칠todo classify()
        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, INPUT_SIZE, INPUT_SIZE, true)
        val byteBuffer = convertBitmapToByteBuffer(scaledBitmap)
        val output = Array(1) { FloatArray(labels.size) }

        // Ejecuci칩n de inferencia
        interpreter?.run(byteBuffer, output)

        val probabilities = output[0]

        // Crear lista de pares (칤ndice, probabilidad) y ordenar por probabilidad descendente
        // Esto permite mostrar primero las predicciones m치s probables
        val sortedResults = probabilities.indices
            .map { index -> index to probabilities[index] }
            .sortedByDescending { it.second }

        // Construcci칩n del texto formateado con todas las predicciones
        val resultText = buildString {
            appendLine("游늵 RESULTADOS COMPLETOS:\n")

            sortedResults.forEachIndexed { position, (index, probability) ->
                val percentage = (probability * 100).toInt()

                // Asignaci칩n de emojis de medalla seg칰n posici칩n en el ranking
                val emoji = when (position) {
                    0 -> "游볞" // Oro: predicci칩n m치s probable
                    1 -> "游볟" // Plata: segunda m치s probable
                    2 -> "游볠" // Bronce: tercera m치s probable
                    else -> "  " // Sin emoji para posiciones inferiores
                }

                appendLine("$emoji ${labels[index]}: $percentage%")
            }
        }

        return resultText.trim()
    }

    /**
     * Convierte un Bitmap de Android a ByteBuffer para TensorFlow Lite.
     *
     * Realiza normalizaci칩n de p칤xeles seg칰n el preprocesamiento de MobileNetV2:
     * - Rango original: [0, 255] (valores RGB de 8 bits)
     * - Rango normalizado: [-1.0, 1.0] (esperado por el modelo)
     *
     * F칩rmula de normalizaci칩n: (pixel - 127.5) / 127.5
     *
     * Orden de canales: RGB (Rojo, Verde, Azul)
     *
     * @param bitmap Imagen redimensionada a 224x224
     * @return ByteBuffer con tensor de entrada de 4 dimensiones
     */
    private fun convertBitmapToByteBuffer(bitmap: Bitmap): ByteBuffer {
        // C치lculo de tama침o del buffer:
        // 4 bytes (float32) 칑 224 p칤xeles 칑 224 p칤xeles 칑 3 canales RGB
        val byteBuffer = ByteBuffer.allocateDirect(4 * INPUT_SIZE * INPUT_SIZE * 3)

        // Configuraci칩n del orden de bytes seg칰n la arquitectura del dispositivo
        // (Little-endian en ARM, que es el est치ndar en Android)
        byteBuffer.order(ByteOrder.nativeOrder())

        // Extracci칩n de valores de p칤xeles del bitmap
        val intValues = IntArray(INPUT_SIZE * INPUT_SIZE)
        bitmap.getPixels(intValues, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)

        // Iteraci칩n por cada p칤xel de la imagen
        var pixel = 0
        for (i in 0 until INPUT_SIZE) {
            for (j in 0 until INPUT_SIZE) {
                val value = intValues[pixel++]

                // EXTRACCI칍N Y NORMALIZACI칍N DE CANALES RGB
                // Android almacena colores en formato ARGB (32 bits)
                // Se extraen los 8 bits de cada canal mediante operaciones bit a bit

                // Canal Rojo: bits 16-23
                byteBuffer.putFloat(((value shr 16 and 0xFF) - 127.5f) / 127.5f)

                // Canal Verde: bits 8-15
                byteBuffer.putFloat(((value shr 8 and 0xFF) - 127.5f) / 127.5f)

                // Canal Azul: bits 0-7
                byteBuffer.putFloat(((value and 0xFF) - 127.5f) / 127.5f)
            }
        }

        return byteBuffer
    }

    /**
     * Libera los recursos del int칠rprete TensorFlow Lite.
     *
     * Debe invocarse cuando el clasificador ya no sea necesario
     * para evitar fugas de memoria nativa (memoria no gestionada por el GC de Java).
     */
    fun close() {
        interpreter?.close()
    }
}