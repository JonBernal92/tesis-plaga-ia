# ================================================================
# CONVERSI√ìN DE MODELO KERAS A TENSORFLOW LITE
# Script para exportar el modelo entrenado a formato compatible con Android
# ================================================================

import tensorflow as tf
import numpy as np
import os

# ----------------------------------------------------------------
# CONFIGURACI√ìN DE ARCHIVOS
# ----------------------------------------------------------------
# Nombre del modelo entrenado previamente (formato Keras .h5)
NOMBRE_MODELO_ENTRENADO = "modelo_mobilenetv2_tomate_plagas.h5" 

# Nombre del archivo de salida optimizado para dispositivos m√≥viles
NOMBRE_MODELO_FINAL = "tomate_final_compatible.tflite"

print(f"Usando TensorFlow versi√≥n: {tf.__version__}")

# Verificaci√≥n de existencia del archivo fuente
if not os.path.exists(NOMBRE_MODELO_ENTRENADO):
    print(f"‚ùå ERROR: No se encuentra el archivo '{NOMBRE_MODELO_ENTRENADO}'")
    print("Debe ejecutar primero el script de entrenamiento.")
    exit()

# ----------------------------------------------------------------
# CARGA DEL MODELO ENTRENADO
# ----------------------------------------------------------------
print("Cargando modelo desde archivo .h5...")

# Se carga el modelo sin recompiarlo (compile=False) ya que solo se necesita
# la arquitectura y los pesos para la conversi√≥n, no los optimizadores de entrenamiento
modelo = tf.keras.models.load_model(NOMBRE_MODELO_ENTRENADO, compile=False)

print("‚úÖ Modelo cargado exitosamente.")
print(f"   - Entrada: {modelo.input_shape}")
print(f"   - Salida: {modelo.output_shape}")

# ----------------------------------------------------------------
# GENERACI√ìN DE DATASET REPRESENTATIVO
# ----------------------------------------------------------------
# El dataset representativo permite al conversor analizar el rango de valores
# que procesar√° el modelo, optimizando la cuantizaci√≥n y mejorando la precisi√≥n
# en dispositivos m√≥viles con recursos limitados

def representative_dataset():
    """
    Genera un conjunto de datos sint√©ticos para calibraci√≥n del modelo.
    
    Este dataset permite al conversor de TensorFlow Lite determinar los rangos
    √≥ptimos de activaci√≥n para cada capa de la red neuronal, resultando en
    una cuantizaci√≥n m√°s precisa sin p√©rdida significativa de exactitud.
    
    Yields:
        list: Lote de 1 imagen de 224x224x3 p√≠xeles en formato float32
    """
    # Se generan 100 ejemplos aleatorios para una calibraci√≥n robusta
    for _ in range(100):
        # Imagen sint√©tica con valores normalizados (rango 0.0 - 255.0)
        # Dimensiones: [batch=1, altura=224, ancho=224, canales=3]
        data = np.random.rand(1, 224, 224, 3) * 255.0
        yield [data.astype(np.float32)]

print("Dataset representativo configurado (100 muestras sint√©ticas).")

# ----------------------------------------------------------------
# CONFIGURACI√ìN DEL CONVERSOR TFLITE
# ----------------------------------------------------------------
print("\nIniciando proceso de conversi√≥n a TensorFlow Lite...")

# Inicializaci√≥n del conversor desde modelo Keras
converter = tf.lite.TFLiteConverter.from_keras_model(modelo)

# --- Optimizaciones de Cuantizaci√≥n ---
# La cuantizaci√≥n reduce el tama√±o del modelo y acelera la inferencia
# convirtiendo pesos de float32 (4 bytes) a int8 (1 byte)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Asignaci√≥n del dataset para calibraci√≥n de cuantizaci√≥n
converter.representative_dataset = representative_dataset

# --- Especificaci√≥n de Operadores Soportados ---
# Se restringe a operadores b√°sicos de TFLite cuantizados a 8 bits
# para garantizar compatibilidad con versiones antiguas del runtime
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

# --- Tipos de Datos de Entrada/Salida ---
# A pesar de la cuantizaci√≥n interna, las interfaces del modelo mantienen
# precisi√≥n float32 para facilitar el preprocesamiento de im√°genes
converter.inference_input_type = tf.float32
converter.inference_output_type = tf.float32

# ----------------------------------------------------------------
# PROCESO DE CONVERSI√ìN
# ----------------------------------------------------------------
print("Ejecutando conversi√≥n (esto puede tomar varios minutos)...")

try:
    # Conversi√≥n del modelo a formato TFLite binario
    tflite_model = converter.convert()
    
    # Escritura del modelo convertido en disco
    with open(NOMBRE_MODELO_FINAL, "wb") as archivo_salida:
        archivo_salida.write(tflite_model)
    
    # C√°lculo del tama√±o final
    tamanio_mb = len(tflite_model) / (1024 * 1024)
    
    print("\n" + "=" * 70)
    print("‚úÖ CONVERSI√ìN COMPLETADA EXITOSAMENTE")
    print("=" * 70)
    print(f"Archivo generado: {NOMBRE_MODELO_FINAL}")
    print(f"Tama√±o del modelo: {tamanio_mb:.2f} MB")
    print(f"Formato: TensorFlow Lite (cuantizado a INT8)")
    print("\nCaracter√≠sticas del modelo optimizado:")
    print("  ‚Ä¢ Inferencia acelerada mediante cuantizaci√≥n")
    print("  ‚Ä¢ Tama√±o reducido (‚âà4x m√°s peque√±o que float32)")
    print("  ‚Ä¢ Compatible con Android API 24+ (armeabi-v7a)")
    print("=" * 70)
    
except Exception as error_conversion:
    # Manejo de fallos durante la conversi√≥n cuantizada
    print(f"\n‚ö†Ô∏è  Error durante conversi√≥n optimizada: {error_conversion}")
    print("\nIntentando conversi√≥n b√°sica sin cuantizaci√≥n...")
    
    # CONVERSI√ìN ALTERNATIVA: Sin optimizaciones de cuantizaci√≥n
    # Se utiliza como fallback cuando la cuantizaci√≥n INT8 falla
    # Produce un modelo m√°s grande pero m√°s compatible
    converter_basico = tf.lite.TFLiteConverter.from_keras_model(modelo)
    
    # Conversi√≥n sin configuraciones adicionales
    tflite_model = converter_basico.convert()
    
    # Guardado del modelo b√°sico
    with open(NOMBRE_MODELO_FINAL, "wb") as archivo_salida:
        archivo_salida.write(tflite_model)
    
    tamanio_mb = len(tflite_model) / (1024 * 1024)
    
    print(f"‚úÖ Conversi√≥n b√°sica completada: {NOMBRE_MODELO_FINAL}")
    print(f"Tama√±o: {tamanio_mb:.2f} MB (sin cuantizaci√≥n)")
    print("Nota: Este modelo es funcional pero ocupa m√°s espacio en memoria.")

# ----------------------------------------------------------------
# INSTRUCCIONES DE IMPLEMENTACI√ìN
# ----------------------------------------------------------------
print("\nüì± PASOS PARA INTEGRACI√ìN EN ANDROID:")
print("‚îÄ" * 70)
print("1. Copiar el archivo a la carpeta de assets del proyecto:")
print(f"   android/app/src/main/assets/{NOMBRE_MODELO_FINAL}")
print("\n2. Actualizar la referencia en TomateClassifier.kt:")
print(f"   loadModelFile(\"{NOMBRE_MODELO_FINAL}\")")
print("\n3. Compilar y ejecutar la aplicaci√≥n en el dispositivo")
print("‚îÄ" * 70)